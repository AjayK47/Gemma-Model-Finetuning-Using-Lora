{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Pre-Processing For GEMMA Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"### Install Necessary Libraries","metadata":{}},{"cell_type":"code","source":"!pip install -q jsonlines\n!pip install -q --upgrade datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-18T12:33:22.713130Z","iopub.execute_input":"2024-03-18T12:33:22.713502Z","iopub.status.idle":"2024-03-18T12:33:55.052893Z","shell.execute_reply.started":"2024-03-18T12:33:22.713472Z","shell.execute_reply":"2024-03-18T12:33:55.051316Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Create Hugging Face API Key and Add to Kaggle\n\n#### Hugging Face >> Tap on Profile >> Settings >> Access Tokens >> Copy Token\n\n#### Kaggle-Notebook >> Add-ons >> Secrets >> Add New Secret","metadata":{}},{"cell_type":"code","source":"# Import Libraries\n\nimport os\nfrom kaggle_secrets import UserSecretsClient","metadata":{"execution":{"iopub.status.busy":"2024-03-18T12:34:02.099947Z","iopub.execute_input":"2024-03-18T12:34:02.100385Z","iopub.status.idle":"2024-03-18T12:34:02.114183Z","shell.execute_reply.started":"2024-03-18T12:34:02.100349Z","shell.execute_reply":"2024-03-18T12:34:02.113005Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nos.environ[\"HF_TOKEN\"] = user_secrets.get_secret(\"HF_TOKEN\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T12:34:05.586481Z","iopub.execute_input":"2024-03-18T12:34:05.587116Z","iopub.status.idle":"2024-03-18T12:34:05.897647Z","shell.execute_reply.started":"2024-03-18T12:34:05.587083Z","shell.execute_reply":"2024-03-18T12:34:05.896548Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## Load the dataset from Hugging Face\n\nfrom datasets import load_dataset\n\ndataset_name = \"BashitAli/Indian_history\" ## Replace with your dataset name \ndataset = load_dataset(dataset_name, split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T12:34:11.199849Z","iopub.execute_input":"2024-03-18T12:34:11.200209Z","iopub.status.idle":"2024-03-18T12:34:21.798119Z","shell.execute_reply.started":"2024-03-18T12:34:11.200180Z","shell.execute_reply":"2024-03-18T12:34:21.796470Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4476ef40e60a4a54910ed0d5119b90da"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 3.47M/3.47M [00:01<00:00, 2.38MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93debd20eb6749b99d9b4631666c6d96"}},"metadata":{}}]},{"cell_type":"markdown","source":"if you dont have your data at hugging face you can just add it to your hugging face repo or load it in here with help of pandas","metadata":{}},{"cell_type":"code","source":"## Lets formatt the dataset in the order GEMMA model CHAT Template\n\nformatted_dataset = []\nfor __, data in enumerate(dataset):\n    text = f\"<bos><start_of_turn>user\\n{data['instruction']}<end_of_turn>\\n<start_of_turn>model\\n{data['response']}<end_of_turn>\\n\"\n    formatted_dataset.append({\"text\": text})\nprint(formatted_dataset[0:2])","metadata":{"execution":{"iopub.status.busy":"2024-03-18T12:34:29.758988Z","iopub.execute_input":"2024-03-18T12:34:29.759588Z","iopub.status.idle":"2024-03-18T12:34:30.436342Z","shell.execute_reply.started":"2024-03-18T12:34:29.759536Z","shell.execute_reply":"2024-03-18T12:34:30.435558Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[{'text': '<bos><start_of_turn>user\\nWhat is the purpose of studying history?<end_of_turn>\\n<start_of_turn>model\\nHistory helps us understand how early humans adapted to their environment and developed civilizations. It involves analyzing society, economy, and culture over time to understand their impact.<end_of_turn>\\n'}, {'text': '<bos><start_of_turn>user\\nHow does a historian evaluate events?<end_of_turn>\\n<start_of_turn>model\\nHistorians assess various situations over a long period, questioning why events occurred and their broader impact on society. They differentiate between fact and fiction, corroborating evidence for accuracy.<end_of_turn>\\n'}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"for more understanding on this particular template, check out this community forum Q&A post https://huggingface.co/google/gemma-7b/discussions/62","metadata":{}},{"cell_type":"code","source":"# convert to json and save the Formatted dataset as jsonl file\nimport jsonlines as jl\nwith jl.open('indian_history_mini.jsonl', 'w') as writer:\n    writer.write_all(formatted_dataset[0:])","metadata":{"execution":{"iopub.status.busy":"2024-03-18T12:34:48.401645Z","iopub.execute_input":"2024-03-18T12:34:48.402164Z","iopub.status.idle":"2024-03-18T12:34:48.566410Z","shell.execute_reply.started":"2024-03-18T12:34:48.402124Z","shell.execute_reply":"2024-03-18T12:34:48.565006Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"You can now download the Formmated dataset from Working folder in Kaggle and add it to your Hugging face repo as dataset to use it while fine tuning","metadata":{}}]}